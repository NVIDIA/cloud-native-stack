- hosts: master
  gather_facts: yes
  vars_files:
    - cns_values.yaml
    - gpu_operator.yaml
  tasks:
    - name: Validate kubernetes cluster is up
      shell:  kubectl cluster-info | grep master
      register: cluster
      failed_when: false
      ignore_errors: yes

    - name: Check Operating System Version
      shell: cat /etc/os-release | grep -iw version | sed 's/VERSION=//g;s/"//g'
      register: osversion
      ignore_errors: yes

    - name: Check Docker Version
      become: true
      when: cns_version <= 3.1
      shell: docker version | grep -i -A2 'Server' | grep Version  | awk '{print $2}'
      register: dockerversion
      ignore_errors: yes

    - name: Check Containerd Version
      become: true
      when: cns_version >= 4.0
      shell: /usr/local/bin/containerd -v | awk '{print $3}'
      register: containerd_version
      ignore_errors: yes

    - name: Check Kubernetes Version
      shell: kubectl version -o json | jq .serverVersion.gitVersion | sed 's/\"//g'
      register: k8sversion
      ignore_errors: yes

    - name: Check Helm Version
      shell: helm version --short | sed 's/v//g;s/\+.*//g'
      register: helmversion
      ignore_errors: yes

    - name: Check Etcd Version
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep 'etcd' | awk -F':' '{print $2}'
      register: etcd_version
      ignore_errors: yes

    - name: Check Nvidia GPU Operator Toolkit versions
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep toolkit | awk -F':' '{print $2}' | awk -F'-' '{print $1}' | head -n1
      register: nvtoolkit
      ignore_errors: yes

    - name: Check Nvidia K8s Device versions
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep 'k8s-device' | head -n1 | awk -F' ' '{print $2}' | awk -F':' '{print $2}' | head -n1 | sed 's/-ubi8//g'
      register: k8sdevice
      ignore_errors: yes

    - name: Check GPU Operator Nvidia Container Driver versions
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep 'driver'  | awk -F':' '{print $2}' | awk -F'-' '{print $1}' | head -n1
      register: nvcdriver
      ignore_errors: yes

    - name: Check GPU Operator Nvidia DGCM Versions
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep 'k8s/dcgm'  |  awk -F':' '{print $2}'  | sed 's/-ubuntu.*//g'
      register: dgcm
      ignore_errors: yes

    - name: Check GPU Operator Node Feature Discovery Versions
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep 'node-feature-discovery' | head -n1 |  awk -F':' '{print $2}'
      register: nodediscover
      ignore_errors: yes

    - name: Check GPU Operator GPU Feature Discovery Versions
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep 'gpu-feature-discovery'  | awk -F' ' '{print $2}' | awk -F':' '{print $2}' | sed 's/-ubi8//g'
      register: gpudiscover
      ignore_errors: yes

    - name: Check Nvidia GPU Operator versions
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep 'nvidia/gpu-operator'  | awk -F':' '{print $2}' | head -n1
      register: gpuoperator
      ignore_errors: yes

    - name: Check Nvidia MIG Maanger versions
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep 'mig-manager'  | awk -F':' '{print $2}' | head -n1 | sed 's/-ubuntu20.04//'g
      register: mig_manager
      ignore_errors: yes

    - name: Check Nvidia validator versions
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep validator | awk '{print $2}' | uniq | awk -F':' '{print $2}' | head -n1
      register: validator
      ignore_errors: yes

    - name: Check Nvidia DCGM Exporter versions
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep dcgm-e | awk '{print $2}' | uniq | awk -F':' '{print $2}' | sed 's/-ubuntu22.04//'g
      register: dcgm_exporter
      ignore_errors: yes

    - name: Check NVIDIA Driver Version
      when: cns_nvidia_driver == true
      shell: nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
      register: nvidia_driver

    - name: Check NVIDIA Container ToolKit Version
      when: cns_docker == true
      become: true
      shell: dpkg -l | grep -i nvidia-container-toolkit | awk '{ print $3}'  | head -n1
      register: nvidia_ct

    - name: Check Mellanox Network Operator version
      when: "enable_network_operator == true"
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep 'network-operator'  | awk -F':' '{print $2}' | head -n1
      register: networkoperator
      ignore_errors: yes

    - name: Check Mellanox MOFED Driver Version
      when: "enable_network_operator == true"
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}"   | grep mofed | awk -F":" '{print $2}' | head -n1
      register: mofed_version
      ignore_errors: yes

    - name: Check RDMA Shared Device Plugin Version
      when: "enable_network_operator == true"
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}"  | grep rdma-shared | awk -F':' '{print $2}' | head -n1
      register: rdma_version
      ignore_errors: yes

    - name: Check SRIOV Device Plugin Version
      when: "enable_network_operator == true"
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}"  | grep sriov-device | awk -F':' '{print $2}' | head -n1
      register: sriov_version
      ignore_errors: yes

    - name: Check Container Networking Plugins Version
      when: "enable_network_operator == true"
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}"  | grep plugins | awk -F':' '{print $2}' | head -n1
      register: cni_version
      ignore_errors: yes

    - name: Check Multus Version
      when: "enable_network_operator == true"
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}"  | grep multus | awk -F':' '{print $2}' | head -n1
      register: multus_version
      ignore_errors: yes

    - name: Check Whereabouts Version
      when: "enable_network_operator == true"
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}"  | grep whereabouts | awk -F':' '{print $2}' | head -n1
      register: whereabouts_version
      ignore_errors: yes

    - name: Check Calico Version
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep 'calico' | awk -F':' '{print $2}' | uniq | head -n1
      register: calico_ver
      ignore_errors: yes

    - name: Check Flannel Version
      shell: kubectl get pods --all-namespaces -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.spec.containers[*].image}{'\n'}" | grep 'flannel' | awk -F':' '{print $2}'
      register: flannel_ver
      ignore_errors: yes

    - name: Check CRI-O Version
      shell: crio -v | head -n1 | awk '{print $NF}'
      register: crio_version
      ignore_errors: yes

    - name: Get CRI-Dockerd version
      shell: cri-dockerd --version | awk '{print $2}'
      register: cridockerd_version
      ignore_errors: yes

    - name: check master node is up and running
      shell: kubectl get nodes | grep -i ready
      register: nodeready
      failed_when: "'NotReady' in nodeready.stdout"
      ignore_errors: yes

    - name: Check all pods are running for Kubernetes
      shell: kubectl get pods --all-namespaces | egrep -iv 'Running|NAME|Completed'
      register: kubepods
      failed_when: kubepods.rc == 0
      ignore_errors: yes

    - name: validate helm installed
      shell: helm ls
      register: helmls
      failed_when: helmls.rc == 1
      ignore_errors: yes

    - name: Collecting Number of GPU's
      shell: "kubectl describe nodes | grep -A 6 Capacity | grep 'nvidia.com/gpu' | awk '{print $2}' | head -n1 | tr -d '\n'"
      register: gpus
      ignore_errors: yes

    - name: Create NVIDIA-SMI yaml
      when: "ansible_distribution == 'RedHat'"
      copy:
        content:  |
                 apiVersion: v1
                 kind: Pod
                 metadata:
                   name: nvidia-smi
                 spec:
                   restartPolicy: OnFailure
                   containers:
                     - name: nvidia-smi
                       image: "nvidia/cuda:12.6.0-base-ubi8"
                       args: ["nvidia-smi"]
        dest: nvidia-smi.yaml

    - name: Create NVIDIA-SMI yaml
      when: "ansible_distribution == 'Ubuntu'"
      copy:
        content:  |
                 apiVersion: v1
                 kind: Pod
                 metadata:
                   name: nvidia-smi
                 spec:
                   restartPolicy: OnFailure
                   containers:
                     - name: nvidia-smi
                       image: "nvidia/cuda:12.6.0-base-ubuntu22.04"
                       args: ["nvidia-smi"]
        dest: nvidia-smi.yaml

    - name: Report Operating System Version of RHEL/CentOS
      when: "ansible_distribution in ['RedHat', 'CentOS']"
      ignore_errors: yes
      debug:
        msg: "RHEL/CentOS Operating System version {{ osversion.stdout }}"

    - name: Report Operating System Version of Ubuntu
      when: "ansible_distribution == 'Ubuntu'"
      ignore_errors: yes
      debug:
        msg: "Ubuntu Operating System version {{ osversion.stdout }}"

    - name: Report Docker Version
      when: cns_version <= 3.1
      ignore_errors: yes
      debug:
        msg: "Docker Version {{ dockerversion.stdout }}"

    - name: Componenets Target Versions Vs Installed Versions
      when: cns_docker == false and cns_version == 14.0 or cns_docker == false and cns_version == 12.3 or cns_docker == false and cns_version == 13.2
      register: compare_140
      args:
        executable: /bin/bash
      shell: |
        echo -e "==========================================================================================="
        echo -e "  Components                          Target Version          ||     Installed Version    "
        echo -e "==========================================================================================="
        echo -e "GPU Operator Version                  {{ release_24_9_2['gpu_operator_version'] }}                 ||     {{ gpuoperator.stdout }}"
        echo -e "NVIDIA Container Driver Version       {{ release_24_9_2['gpu_driver_version'] }}               ||     {{ nvcdriver.stdout }}"
        echo -e "GPU Operator NV Toolkit Driver        {{ release_24_9_2['container_toolkit'] }}                 ||     {{ nvtoolkit.stdout }}"
        echo -e "K8sDevice Plugin Version              {{ release_24_9_2['device_plugin']  }}                 ||     {{ k8sdevice.stdout }}"
        echo -e "Data Center GPU Manager(DCGM) Version {{ release_24_9_2['dcgm_exporter_version'] }}             ||     {{ dcgm_exporter.stdout }}"
        echo -e "Node Feature Discovery Version        {{ release_24_9_2['nfd_version'] }}                 ||     {{ nodediscover.stdout }}"
        echo -e "GPU Feature Discovery Version         {{ release_24_9_2['gfd_version'] }}                  ||     {{ gpudiscover.stdout }}"
        echo -e "NVIDIA validator version              {{ release_24_9_2['validator_version'] }}                 ||     {{ validator.stdout }}"
        echo -e "NVIDIA MIG Manager version            {{ release_24_9_2['mig_manager_version'] }}                  ||     {{ mig_manager.stdout }}"
        echo -e
        echo -e "NOTE: NVIDIA Mig Manager is valid for only A100 and A30 and H100 GPU's"
        echo -e
        echo -e "Please validate between Target Version and Installed Version listed above"

    - name: Componenets Target Versions Vs Installed Versions
      when: cns_docker == false and cns_version == 15.0 or cns_docker == false and cns_version == 13.3 or cns_docker == false and cns_version == 14.1
      register: compare_150
      args:
        executable: /bin/bash
      shell: |
        echo -e "==========================================================================================="
        echo -e "  Components                          Target Version          ||     Installed Version    "
        echo -e "==========================================================================================="
        echo -e "GPU Operator Version                  {{ release_25_3_0['gpu_operator_version'] }}                 ||     {{ gpuoperator.stdout }}"
        echo -e "NVIDIA Container Driver Version       {{ release_25_3_0['gpu_driver_version'] }}               ||     {{ nvcdriver.stdout }}"
        echo -e "GPU Operator NV Toolkit Driver        {{ release_25_3_0['container_toolkit'] }}                 ||     {{ nvtoolkit.stdout }}"
        echo -e "K8sDevice Plugin Version              {{ release_25_3_0['device_plugin']  }}                 ||     {{ k8sdevice.stdout }}"
        echo -e "Data Center GPU Manager(DCGM) Version {{ release_25_3_0['dcgm_exporter_version'] }}             ||     {{ dcgm_exporter.stdout }}"
        echo -e "Node Feature Discovery Version        {{ release_25_3_0['nfd_version'] }}                 ||     {{ nodediscover.stdout }}"
        echo -e "GPU Feature Discovery Version         {{ release_25_3_0['gfd_version'] }}                  ||     {{ gpudiscover.stdout }}"
        echo -e "NVIDIA validator version              {{ release_25_3_0['validator_version'] }}                 ||     {{ validator.stdout }}"
        echo -e "NVIDIA MIG Manager version            {{ release_25_3_0['mig_manager_version'] }}                  ||     {{ mig_manager.stdout }}"
        echo -e
        echo -e "NOTE: NVIDIA Mig Manager is valid for only A100 and A30 and H100 GPU's"
        echo -e
        echo -e "Please validate between Target Version and Installed Version listed above"

    - name: Componenets Target Versions Vs Installed Versions
      when: cns_docker == false and cns_version == 16.0 or cns_docker == false and cns_version == 15.1 or cns_docker == false and cns_version == 14.2
      register: compare_160
      args:
        executable: /bin/bash
      shell: |
        echo -e "==========================================================================================="
        echo -e "  Components                          Target Version          ||     Installed Version    "
        echo -e "==========================================================================================="
        echo -e "GPU Operator Version                  {{ release_25_3_2['gpu_operator_version'] }}                 ||     {{ gpuoperator.stdout }}"
        echo -e "NVIDIA Container Driver Version       {{ release_25_3_2['gpu_driver_version'] }}               ||     {{ nvcdriver.stdout }}"
        echo -e "GPU Operator NV Toolkit Driver        {{ release_25_3_2['container_toolkit'] }}                 ||     {{ nvtoolkit.stdout }}"
        echo -e "K8sDevice Plugin Version              {{ release_25_3_2['device_plugin']  }}                 ||     {{ k8sdevice.stdout }}"
        echo -e "Data Center GPU Manager(DCGM) Version {{ release_25_3_2['dcgm_exporter_version'] }}             ||     {{ dcgm_exporter.stdout }}"
        echo -e "Node Feature Discovery Version        {{ release_25_3_2['nfd_version'] }}                 ||     {{ nodediscover.stdout }}"
        echo -e "GPU Feature Discovery Version         {{ release_25_3_2['gfd_version'] }}                  ||     {{ gpudiscover.stdout }}"
        echo -e "NVIDIA validator version              {{ release_25_3_2['validator_version'] }}                 ||     {{ validator.stdout }}"
        echo -e "NVIDIA MIG Manager version            {{ release_25_3_2['mig_manager_version'] }}                  ||     {{ mig_manager.stdout }}"
        echo -e
        echo -e "NOTE: NVIDIA Mig Manager is valid for only A100 and A30 and H100 GPU's"
        echo -e
        echo -e "Please validate between Target Version and Installed Version listed above"

    - name: Componenets Target Versions Vs Installed Versions
      when:  cns_version == 14.0 and cns_docker == true or cns_version == 12.3 and cns_docker == true or cns_version == 13.2 and cns_docker == true
      register: compare_140docker
      args:
        executable: /bin/bash
      shell: |
        echo -e "==========================================================================================="
        echo -e "  Components                          Target Version          ||     Installed Version    "
        echo -e "==========================================================================================="
        echo -e "GPU Operator Version                  {{ release_24_9_2['gpu_operator_version'] }}                ||     {{ gpuoperator.stdout }}"
        echo -e "NVIDIA Container Driver Version       {{ release_24_9_2['gpu_driver_version'] }}             ||     {{ nvidia_driver.stdout }}"
        echo -e "NVIDIA Toolkit Driver                 {{ release_24_9_2['container_toolkit'] }}                 ||     {{ nvidia_ct.stdout }}"
        echo -e "K8sDevice Plugin Version              {{ release_24_9_2['device_plugin']  }}                 ||     {{ k8sdevice.stdout }}"
        echo -e "Data Center GPU Manager(DCGM) Version {{ release_24_9_2['dcgm_exporter_version'] }}             ||     {{ dcgm_exporter.stdout }}"
        echo -e "Node Feature Discovery Version        {{ release_24_9_2['nfd_version'] }}                 ||     {{ nodediscover.stdout }}"
        echo -e "GPU Feature Discovery Version         {{ release_24_9_2['gfd_version'] }}                  ||     {{ gpudiscover.stdout }}"
        echo -e "NVIDIA validator version              {{ release_24_9_2['validator_version'] }}                 ||     {{ validator.stdout }}"
        echo -e "NVIDIA MIG Manager version            {{ release_24_9_2['mig_manager_version'] }}                  ||     {{ mig_manager.stdout }}"
        echo -e
        echo -e "NOTE: NVIDIA Mig Manager is valid for only A100 and A30 and H100 GPU's"
        echo -e
        echo -e "Please validate between Target Version and Installed Version listed above"

    - name: Componenets Target Versions Vs Installed Versions
      when:  cns_version == 15.0 and cns_docker == true or cns_version == 13.3 and cns_docker == true or cns_version == 14.1 and cns_docker == true
      register: compare_150docker
      args:
        executable: /bin/bash
      shell: |
        echo -e "==========================================================================================="
        echo -e "  Components                          Target Version          ||     Installed Version    "
        echo -e "==========================================================================================="
        echo -e "GPU Operator Version                  {{ release_25_3_0['gpu_operator_version'] }}                ||     {{ gpuoperator.stdout }}"
        echo -e "NVIDIA Container Driver Version       {{ release_25_3_0['gpu_driver_version'] }}             ||     {{ nvidia_driver.stdout }}"
        echo -e "NVIDIA Toolkit Driver                 {{ release_25_3_0['container_toolkit'] }}                 ||     {{ nvidia_ct.stdout }}"
        echo -e "K8sDevice Plugin Version              {{ release_25_3_0['device_plugin']  }}                 ||     {{ k8sdevice.stdout }}"
        echo -e "Data Center GPU Manager(DCGM) Version {{ release_25_3_0['dcgm_exporter_version'] }}             ||     {{ dcgm_exporter.stdout }}"
        echo -e "Node Feature Discovery Version        {{ release_25_3_0['nfd_version'] }}                 ||     {{ nodediscover.stdout }}"
        echo -e "GPU Feature Discovery Version         {{ release_25_3_0['gfd_version'] }}                  ||     {{ gpudiscover.stdout }}"
        echo -e "NVIDIA validator version              {{ release_25_3_0['validator_version'] }}                 ||     {{ validator.stdout }}"
        echo -e "NVIDIA MIG Manager version            {{ release_25_3_0['mig_manager_version'] }}                  ||     {{ mig_manager.stdout }}"
        echo -e
        echo -e "NOTE: NVIDIA Mig Manager is valid for only A100 and A30 and H100 GPU's"
        echo -e
        echo -e "Please validate between Target Version and Installed Version listed above"

    - name: Componenets Target Versions Vs Installed Versions
      when:  cns_version == 15.1 and cns_docker == true or cns_version == 14.2 and cns_docker == true or cns_version == 16.0 and cns_docker == true
      register: compare_160docker
      args:
        executable: /bin/bash
      shell: |
        echo -e "==========================================================================================="
        echo -e "  Components                          Target Version          ||     Installed Version    "
        echo -e "==========================================================================================="
        echo -e "GPU Operator Version                  {{ release_25_3_2['gpu_operator_version'] }}                ||     {{ gpuoperator.stdout }}"
        echo -e "NVIDIA Container Driver Version       {{ release_25_3_2['gpu_driver_version'] }}             ||     {{ nvidia_driver.stdout }}"
        echo -e "NVIDIA Toolkit Driver                 {{ release_25_3_2['container_toolkit'] }}                 ||     {{ nvidia_ct.stdout }}"
        echo -e "K8sDevice Plugin Version              {{ release_25_3_2['device_plugin']  }}                 ||     {{ k8sdevice.stdout }}"
        echo -e "Data Center GPU Manager(DCGM) Version {{ release_25_3_2['dcgm_exporter_version'] }}             ||     {{ dcgm_exporter.stdout }}"
        echo -e "Node Feature Discovery Version        {{ release_25_3_2['nfd_version'] }}                 ||     {{ nodediscover.stdout }}"
        echo -e "GPU Feature Discovery Version         {{ release_25_3_2['gfd_version'] }}                  ||     {{ gpudiscover.stdout }}"
        echo -e "NVIDIA validator version              {{ release_25_3_2['validator_version'] }}                 ||     {{ validator.stdout }}"
        echo -e "NVIDIA MIG Manager version            {{ release_25_3_2['mig_manager_version'] }}                  ||     {{ mig_manager.stdout }}"
        echo -e
        echo -e "NOTE: NVIDIA Mig Manager is valid for only A100 and A30 and H100 GPU's"
        echo -e
        echo -e "Please validate between Target Version and Installed Version listed above"

    - name: Componenets Target Versions Vs Installed Versions
      ignore_errors: yes
      register: stack_versions
      args:
        executable: /bin/bash
      shell: |
        echo -e "==========================================================================================="
        echo -e "  Components                          Installed Version    "
        echo -e "==========================================================================================="
        echo -e "GPU Operator Version                  {{ gpuoperator.stdout }}"
        echo -e "Containerd Version                    {{ containerd_version.stdout }}"
        echo -e "Kubernetes Version                    {{ k8sversion.stdout }}"
        echo -e "Helm Version                          {{ helmversion.stdout }}"
        echo -e "Etcd Version                          {{ etcd_version.stdout }}"
        echo -e "CRI-O Version                         {{ crio_version.stdout }}"
        echo -e "CRI-Dockerd Version                   {{ cridockerd_version.stdout }}"
        echo -e "Calico Version                        {{ calico_ver.stdout }}"
        echo -e

    - name: Componenets Target Versions Vs Installed Versions
      when: "enable_network_operator == true"
      ignore_errors: yes
      register: network_stack_versions
      args:
        executable: /bin/bash
      shell: |
        echo -e "==========================================================================================="
        echo -e "  Components                          Installed Version    "
        echo -e "==========================================================================================="
        echo -e "Network Operator version            {{ networkoperator.stdout }}"
        echo -e "Mellanox MOFED Driver version       {{ mofed_version.stdout }}"
        echo -e "RDMA Shared Device Plugin version   {{ rdma_version.stdout }}"
        echo -e "SRIOV Device Plugin version         {{ sriov_version.stdout }}"
        echo -e "Container Networking Plugin version {{ cni_version.stdout }}"
        echo -e "Multus version                      {{ multus_version.stdout }}"
        echo -e "Container Whereabouts version       {{ whereabouts_version.stdout }}"
        echo -e

    - name: Validate the GPU Operator pods State
      shell: kubectl get pods --all-namespaces | egrep -v 'kube-system|NAME'
      register: pods
      failed_when: pods.rc == 1
      ignore_errors: yes

    - name: Validating the CUDA with GPU
      shell: kubectl run cuda-vector-add --rm -t -i --restart=Never --image=k8s.gcr.io/cuda-vector-add:v0.1
      when: ansible_architecture == 'x86_64'
      register: cuda
      ignore_errors: yes
      async: 60

    - name: Validating the nvidia-smi on NVIDIA Cloud Native Stack
      shell: "kubectl delete -f nvidia-smi.yaml; sleep 10; kubectl apply -f nvidia-smi.yaml; sleep 25; kubectl logs nvidia-smi"
      when: cns_version >= 7.0
      register: smi
      ignore_errors: yes
      async: 60

    - name: Clean up pods if exists
      shell: kubectl delete pod cuda-vector-add nvidia-smi
      ignore_errors: true
      no_log: true
      failed_when: false

    - name: Report Stack Version
      when: "enable_network_operator == true"
      debug:
        msg: "{{ network_stack_versions.stdout_lines }}"

    - name: Report GPU Operator Pods
      debug:
        msg: "{{ pods.stdout_lines }}"

    - name: Report Versions
      when:  cns_version == 14.0 and cns_docker == false or cns_version == 12.3 and cns_docker == false or cns_version == 13.2 and cns_docker == false
      debug:
        msg: "{{ compare_140.stdout_lines }}"

    - name: Report Versions
      when:  cns_version == 14.0 and cns_docker == true or cns_version == 12.3 and cns_docker == true or cns_version == 13.2 and cns_docker == true
      debug:
        msg: "{{ compare_140docker.stdout_lines }}"

    - name: Report Versions
      when:  cns_version == 15.0 and cns_docker == false or cns_version == 13.3 and cns_docker == false or cns_version == 14.1 and cns_docker == false
      debug:
        msg: "{{ compare_150.stdout_lines }}"

    - name: Report Versions
      when:  cns_version == 16.0 and cns_docker == false or cns_version == 15.1 and cns_docker == false or cns_version == 14.2 and cns_docker == false
      debug:
        msg: "{{ compare_160.stdout_lines }}"

    - name: Report Versions
      when:  cns_version == 15.0 and cns_docker == true or cns_version == 13.3 and cns_docker == true or cns_version == 14.1 and cns_docker == true
      debug:
        msg: "{{ compare_150docker.stdout_lines }}"

    - name: Report Versions
      when:  cns_version == 16.0 and cns_docker == true or cns_version == 15.1 and cns_docker == true or cns_version == 14.2 and cns_docker == true
      debug:
        msg: "{{ compare_160docker.stdout_lines }}"

    - name: Report Stack Version
      debug:
        msg: "{{ stack_versions.stdout_lines }}"

    - name: Report Nvidia SMI Validation
      when: cns_version >= 7.0
      ignore_errors: yes
      debug:
        msg: "{{ smi.stdout_lines }}"

    - name: Report Cuda Validation
      when: ansible_architecture == 'x86_64'
      ignore_errors: yes
      debug:
        msg: "{{ cuda.stdout_lines }}"

    - name: Status Check
      shell: echo "All tasks should be changed or ok, if it's failed or ignoring means that validation task failed."
      register: check

    - debug:
        msg: "{{ check.stdout }}"